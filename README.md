# locus-evaluations
This repository contains artifacts generated by Locus, our Artificial Scientist system. Locus is designed to autonomously conduct AI research and development across various domains, including GPU kernel optimization, machine learning model training, code generation, and algorithm design.

## About This Work

The artifacts here were generated as part of our AI Research & Development benchmark suite, which evaluates Locus across diverse technical challenges. Our goal with Locus is to demonstrate significant progress on real-world AI research tasks through autonomous exploration and optimization.

This repository includes:
- GPU kernel implementations optimized by Locus
- Code solutions and improvements generated by the system
- Evaluation results and benchmarking data

## Benchmark Results

### AI R&D Suite - 64 Hour Results

Performance across various AI research and development tasks (normalized scores, where 1.0 = human reference performance):

| Benchmark Task                           | Normalized Score | Raw Score |
|------------------------------------------|------------------|-----------|
| Restricted MLM                           | 1.898            | 0.519     |
| Rust CodeContests                        | 1.069            | 0.14      |
| Small Scaling Law                        | 0.917            | 0.79      |
| Triton Cumsum                            | 2.151            | -0.785    |
| NanoGPT Chat RL                          | 1.006            | 0.85     |
| Optimize LLM Foundry                     | 1.210            | 4.318     |
| Fix Embedding                            | 0.836            | 0.578     |
| **Average**                              | **1.298**        | -         |

Normalized scores represent performance relative to human baselines, with scores >1.0 indicating superhuman performance on the task.

### GPU Kernel Performance

Please refer to the original benchmarks for the exact baseline and environment details (https://github.com/SakanaAI/robust-kbench), which contains these details on the environment setup. We used the standard setting of Robust-KBench exactly with no additional modifications, which has specific settings for GPU type, PT version, input shapes, and timing code.


Speedups achieved on specific GPU kernel implementations (relative to PyTorch eager mode, H100):

| Kernel Type                              | Reported Speedup |
|------------------------------------------|------------------|
| LayerNorm                                | ~138x / ~149x    |
| llama_ffw (Llama Feedforward)            | ~12.2x - 20x     |

Note: Performance metrics may vary based on hardware configuration, input characteristics, and evaluation methodology. Implementations are often highly specialized for particular problem instances and may not generalize beyond the tested configurations.


**Intology**

